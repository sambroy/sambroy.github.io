---
layout: post
title:  "Short notes - Mogrifier LSTM"
date:   2020-02-25 18:30:15 -0800
categories: jekyll update
---

Short notes on Mogrifier LSTM:

Overall objective of the paper:
How do we _inject_ context into the embeddings of a LSTM? Note, that the hidden state
of the LSTM does contain context-specific info, but how do we have the hidden state play
more into the embeddings generated by the LSTM?

The paper takes a fresh look
at the traditional LSTM, and the "gates" in there.
First, the vanilla LSTM:

![LSTM](../../assets/lstm.png)

Some insights:
* the `i` gate essentially "scales" the _rows_ of the weight matrix W_j. What? Look at the equation

* motivated by the above, equip the LSTM with gates that scale the _columns_ of the
weight matrices.


# References:
1. [Mogrifier LSTM](https://arxiv.org/abs/1909.01792)
2. [Mogrifier LSTM openreview](https://openreview.net/forum?id=SJe5P6EYvS)
